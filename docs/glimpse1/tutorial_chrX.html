<!doctype html>
<html lang="en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-2TSEMF47BK"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		gtag('config', 'G-2TSEMF47BK');
	</script>
	
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
		
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="srubinac" >

    <title>GLIMPSE</title>
    <link rel="icon" href="images/branding/glimpse_icon.png">
    
    <!-- Bootstrap core CSS -->
    <link href="./css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="./css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./css/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <!-- JQuery -->
    <script type="text/javascript" src="./script/jquery-1.12.4.min.js"></script>
    <script type="text/javascript" src="./script/bootstrap.min.js"></script>
    <script type="text/javascript" src="./script/docs.min.js"></script>
    <!-- chart JS -->
   	<script type="text/javascript" src="script/Chart.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script type="text/javascript" src="./script/ie10-viewport-bug-workaround.js"></script>
	<!-- Custom styles for this template -->
    <link href="./css/theme.css" rel="stylesheet">
    <!-- Script to load navbar code -->
	<script>
		$(function() {
			$("#navbarbox").load("navbar.html");
		});
    </script> 
</head>

<body>

	<!-- NAVBAR -->
	<nav class="navbar navbar-inverse navbar-fixed-top">
	<div class="container" id="navbarbox"></div>
    </nav>
    
    <!-- CONTENT -->
    <div class="container theme-showcase" role="main">
		<div id="run_preliminaries" class="page-header">
	    	<h1>1. Datasets and preliminaries</h1>
		</div>
		<div class="alert alert-warning" role="alert">
	27/11/2022: This page describes the <b>GLIMPSE1</b> method. <b>GLIMPSE1</b> is recommended to the users who want to use the joint model, for imputation of >1x data and a moderate sized reference panels. For large reference panels and lower coverages, we recommend the use of the <a href="https://github.com/odelaneau/GLIMPSE"><b>GLIMPSE2</b> method</a>
		</div>
		<p>
		GLIMPSE is a software for imputation and phasing of low-coverage datasets in the form of <b>genotype gikelihoods</b> (GLs) at all variant positions.
		This tutorial requires GLIMPSE v1.1.0 (or later) and <a href="http://www.htslib.org/">HTSlib and BCFtools</a> v1.10 (or later). 
		Here we also used BCFtools to compute genotype likelihoods.
		<br>
		<br>
		In this tutorial, we show how to run GLIMPSE to perform <b>chromosome X imputation</b>. Imputation of chromosome X is different from autosomes, 
		as chromosome X contains a non pseudo-autosomal region (<b>non-PAR</b>) where males are haploid and females are diploids. The chromosome also
		contains two pseudo-autosomal regions (PAR1, PAR2), where all samples are diploid. PAR1 and PAR2 are both at the end of the chromosomes. 
		A schematic representation of the regions of the chromosome is given below:<br><br>
		
		<div style="text-align: center;"><img src="images/tutorials/chrX.png" width="1024" height="80" alt="ChrX"></div><br>
		
		This tutorial describes the process of getting refined genotype and haplotype calls starting from aligned sequencing reads data (BAM/CRAM file) for the <b>non-PAR region of chromosome X</b>.
		Imputation of PAR regions of the chromosome is not performed here, as it is not conceptually different from imputation of autosomes. 
		<br>
		<br>	
		The data and the scripts for this tutorial can be downloaded <a href="https://drive.switch.ch/index.php/s/9HEdWR1T8ouRTfW">HERE</a>.
		<br>
		A minimal set of data to run this pipeline can be found in the folder <code>tutorial_chrX</code>. Here we assume that the folder is located as a subfolder of the GLIMPSE installation: <code>tutorial_chrX</code>.
		All datasets used here are in GRCh38/hg38 genome assembly
		<br>
		<br>
		A dataset containing chromosome X downsampled 1x sequencing reads (BAM files) for 2 individuals (one male and one female) from ASW population is provided with this tutorial, 
		together with a reference genome FASTA file needed for genotype likelihood computations.
		</p>

		<div class="well">
			<h3>1.1. Setting the environment and binaries</h3>	
			<p>All scripts have been written assuming <code>&nbsp;>GLIMPSE/tutorial_chrX/</code> as current directory. Therefore, we move to the tutorial_chrX directory:
			<p style="text-indent:-5px ! important;"><code>&nbsp;> cd GLIMPSE/tutorial_chrX/</code></p>
			<p>From this folder we build all the GLIMPSE software needed (chunk, phase, ligate, sample and concordance). 
			For this reason, we require that GLIMPSE can correctly compile on your machine and you might be required to edit the Makefiles manually. 
			See <a href="installation.html">installation instructions</a> if there are any problems at this stage. 
			We created a script to configure a directory containing symbolic links to the GLIMPSE binaries we will need later.
			To run the setup script, simply run:</p>
			<p style="text-indent:-5px ! important;"><code>&nbsp;> ./step1_script_setup.sh</code></p>
			<p>If the script runs correctly, the software compiles and the bin folder containing symbolic links to the binaries has been created, everything is correctly setup.</p>
		</div>
		<div class="well">
			<h3>1.2. Low coverage reads</h3>
				
			<p>
			In this example we downsampled the publicly available 30x data available for ASW population as part of the 1000 Genomes Project.
			We downloaded the full dataset, kept only non-PAR chromosome X reads and downsampled to 1x. The resulting BAM file can be found in: 
			</p>
			
			<p style="text-indent:-5px ! important;"><code>asw_1x_bam/*.bam[.bai]</code>, where each bam file in the folder represents a single sample (2 in total).</p>
		</div>
			    	
		<div id="run_reference_panel" class="page-header">
	    		<h1>2. Reference panel preparation</h1>
		</div> 
		<p>
		In order to run accurate imputation we recommend to use a targeted reference with ancestry related to the target samples, if possible. 
		For this tutorial we use the 1000 Genomes Project phase 3 reference panel. 
		Since the reference panel contains data of our target samples, we need to remove them from the reference panel. 
		This steps download the 1000 genomes b38 data from the EBI ftp site and remove the target samples from it.
		</p>
		<div class="well">
			<h3>2.1. Download of the reference panel files</h3>

			<p>
			The 1000 Genomes phase 3 reference panel is publicly available at EBI 1000 genomes ftp site. 
			We can download chromosome X data using:
			</p>
		
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/ALL.chrX_GRCh38.genotypes.20170504.vcf.gz{,.tbi}
			</code></p>
			The reference panel size is approximately 950 MB.
		</div>
		<div class="well">
			<h3>2.2. Remove ASW samples from the reference panel and basic QC</h3>
			<p> 
			We use BCFtools to remove ASW samples from the reference panel and export the dataset in BCF file format (for efficiency reasons). 
			We also performs a basic QC step that includes:
			<ol>
				<li>Generate a text file containing space-spearated old and new chromosome names. This is required to rename the numerical chromosome names with 'chr' tag. Apply the new chromosome names with 'bcftools annotate'.</li>
				<li>Keep only SNPs and remove multiallelic records.</li>
			</ol> 
			The original reference panel files are then deleted from the main tutorial_chrX folder:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> for CHR in {1..23} X ; do <br>
			&nbsp;> echo ${CHR} chr${CHR}<br>
			&nbsp;> done >> chr_names.txt<br>
			<br>
			&nbsp;> CHR=X<br>
			&nbsp;> bcftools annotate --rename-chrs chr_names.txt \<br>
			&nbsp;> &nbsp;&nbsp;&nbsp;&nbsp;ALL.chr${CHR}_GRCh38.genotypes.20170504.vcf.gz -Ou | \<br>
			&nbsp;> bcftools view -m 2 -M 2 -v snps -S ^NA19625,NA19703 --threads 4 -Ob -o reference_panel/1000GP.chr${CHR}.filt.bcf<br>
			&nbsp;> bcftools index -f reference_panel/1000GP.chrX.filt.bcf<br>
			&nbsp;> rm ALL.chrX_GRCh38.genotypes.20170504.vcf.gz*<br>
			&nbsp;> rm chr_names.txt<br>
			</code></p>
			
			<p>
			The resulting reference panel files can be found in: 
			</p>
			
			<p style="text-indent:-5px ! important;"><code>reference_panel/1000GP.chrX.filt.bcf[.csi]</code></p>
			
			<p>
			The reference panel can now be used for genotype likelihoods calculations (only the sites, not the data) and imputation.
			</p>
		</div>
		    
		<div id="run_likelihoods" class="page-header">
	    	<h1>3. Computation of genotype likelihoods</h1>
		</div>
		
		<p>
		GLIMPSE requires input data to take the form of <b>Genotype Likelihoods</b> (GLs).
		GLs need to be computed at all target individuals and <b>all variant sites present in the reference panel</b> of haplotypes used for the imputation.
		In this section, we describe a simple procedure to compute GLs from sequencing data using BCFtools.
		However, other callers, such as GATK for instance, can be also considered as soon as the GLs are encoded in a VCF/BCF file using the FORMAT/PL field.
		</p>
		
		<p><b><span style="font-size: larger;">Please note that BCFtools does not call correctly genotype likelihoods for indels and this might affect the quality of the imputation even at non-indels.
		For this reason in this tutorial we only focus on bi-allelic SNPs.</span></b></p>
			
		<div class="well">
			<h3>3.1. Extracting variable positions in the reference panel</h3>
				
			<p>
			We want this information to tell BCFtools at which position to make a call.
			Since BCFtools does not seem to compute correctly genotype likelihood for indels, here we only focus on SNPs (however, GLIMPSE can impute any type of variants as soon it is bi-allelic and has GLs being properly defined).
			To perform the extraction from the chromosome X of a reference panel <code>1000GP.chrX.filt.bcf</code>, run first BCFtools as follows:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> bcftools view -G -m 2 -M 2 -v snps reference_panel/1000GP.chrX.filt.bcf -Oz -o reference_panel/1000GP.chrX.filt.sites.vcf.gz<br>
			&nbsp;> bcftools index -f reference_panel/1000GP.chrX.filt.sites.vcf.gz 
			</code></p>
			
			<p>Then, convert the output file <code>1000GP.chrX.filt.sites.vcf.gz </code> into TSV format and index the file using tabix (requires htslib in PATH), using this command:</p>
			
			<p style="text-indent:-5px ! important;">
			<code> 
			&nbsp;> bcftools query -f'%CHROM\t%POS\t%REF,%ALT\n' reference_panel/1000GP.chrX.filt.sites.vcf.gz | bgzip -c > reference_panel/1000GP.chrX.filt.sites.tsv.gz<br>
			&nbsp;> tabix -s1 -b2 -e2 reference_panel/1000GP.chrX.filt.sites.tsv.gz
			</code>
			</p>
			
			<p>In a general pipeline, we should generate this pair of files (*.vcf.gz + *.tsv.gz) for all chromosome separately.</p>
		</div>
		
		<div class="well">
			<h3>3.2. Computing GLs for each individual at specific positions</h3>

			<p>
			Once ready the position files, we can then start performing the calling step.
			We use the downsampled 1x BAM files generated in section 1.1 <code>asw_1x_bam/*.chrX.1x.bam</code>.
			<br>
			BCFtools requires the reference genome in order to align the BAM file. We used the reference genome version used by the 1000 Genomes Project (<code>reference_genome/hs38DH.chrX.fa.gz[.fai,.gzi]</code>)
			<br>
			We can run the following command:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> list.txt<br>
			&nbsp;> FILES=asw_1x_bam/asw_samples/*<br>
			&nbsp;> for file in $FILES; do<br>
			&nbsp;>     f=$(basename $file)<br>
			&nbsp;>     BAM=asw_1x_bam/${f}.bam<br>
			&nbsp;>     VCF=reference_panel/1000GP.chrX.filt.sites.vcf.gz<br>
			&nbsp;>     TSV=reference_panel/1000GP.chrX.filt.sites.tsv.gz<br>
			&nbsp;>     REFGEN=reference_genome/hs38DH.chrX.fa.gz<br>
			&nbsp;>     OUT=asw_1x_vcf/${f}.chrX.1x.vcf.gz<br>			
			&nbsp;>     bcftools mpileup -f ${REFGEN} -I -E -a 'FORMAT/DP' -T ${VCF} -r chrX ${BAM} -Ou | bcftools call --ploidy GRCh38 -S asw_1x_bam/asw_samples/${f} -Aim -C alleles -T ${TSV} -Oz -o ${OUT} <br>
			&nbsp;>     bcftools index -f ${OUT}<br>
			&nbsp;>     ls ${OUT} >> list.txt<br>
			&nbsp;> done<br>
			</code></p>
			
			<p>Note here, that we use <code>-T reference_panel/1000GP.chrX.filt.sites.<b>vcf</b>.gz</code> in the first part of the command line and <br>
			<code>-T reference_panel/1000GP.chrX.filt.sites.<b>tsv</b>.gz</code> in the second part of the command line.</p>
			<p>You may also tune the options of BCFtools to your specific needs, requirements and data.</p>
			<p>As an output of this step we have a VCF file format containing genotype likelihoods at each site in the reference panel. </p>
		</div>
		<div class="well">
			<h3>3.3. Merging genotype likelihoods of multiple individuals</h3>
			<p>As we have multiple target individuals, an additional step is to generate a single file containing genotype likelihoods for all target individuals. 
			This can be easily done using BCFtools, for example:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> bcftools merge -m none -r chrX:2781480-155701382 -Oz -o asw_1x_vcf/merged.chrX.1x.vcf.gz -l list.txt<br>
			&nbsp;> bcftools index -f asw_1x_vcf/merged.chrX.1x.vcf.gz<br>
			&nbsp;> rm list.txt
			</code></p>
			
			<p>Where <code>list.txt</code> is a text file containing the full list of VCF/BCF files containing GLs of each target individual in the study, one individual file per line. 
			The resulting file must be indexed and can be used in the subsequent steps of the pipeline.</p>
			
		</div>
		
		<div id="run_chunk" class="page-header">
	    	<h1>4. Split the genome into chunks</h1>
		</div>
		
		<p>
		One important step prior is to define the chunks where to run imputation and phasing. 
		This step is not trivial because different long regions increase the running time, but small regions can drastically decrease accuracy. 
		Also there are several variables to take into account: the amount of missingness in the defined region and the length in Mb. 
		For these reasons we developed a tool in the GLIMPSE suite (GLIMPSE_chunk) that is able to quickly generate imputation chunks taking into account all this information.
		</p>
		
		<div class="well">
			<h3>4.1. Chunking a chromosome</h3>
				
			<p>
			We use GLIMPSE_chunk to generate imputation regions for the full non-PAR region of chromosome X, modifying few default parameters in this way:
			</p>
			
			<p style="text-indent:-5px ! important;"><code> 
			&nbsp;> ./bin/GLIMPSE_chunk --input reference_panel/1000GP.chrX.filt.sites.vcf.gz --region chrX:2781480-155701382 --output chunks.chrX.txt
			</code></p>			
			This generates a file containing the imputation chunks and larger chunks including buffers that we will use to run GLIMPSE_phase. 		
		</div>
		
		<div id="run_phase" class="page-header">
	    	<h1>5. Impute and phase a whole chromosome</h1>
	    	<p>
	    	The core of GLIMPSE is the GLIMPSE_phase method. The algorithm works by iteratively refining the genotype likelihoods of the target individuals in the study. 
	    	The output of the method is a VCF/BCF file containing:
	    	<ul>
	    		<li>the best guess genotype in the FORMAT/GT field
	    		<li>the imputed genotype dosage in the FORMAT/DS field
	    		<li>the genotype probabilities in the FORMAT/GP field
	    		<li>the last (max 15) sampled haplotypes in the FORMAT/HS field
	    	</ul> 
	    	Other relevant information include the INFO score computed at each variant against the reference panel allele frequency and the estimated allele frequency, obtained from the genotype dosages (and <b>not</b> from the best guess genotypes).
	    	</p>
	    	<div class="well">
				<h3>5.1. Running GLIMPSE</h3>
				
				<p>
				To run GLIMPSE_phase we only need to run a job for each imputation chunk. Each job runs on 4 threads in this example. 
				Input data are the dataset containing the genotype likelihoods, a reference panel of haplotypes, a fine-scale genetic map (e.g. from the International HapMap project) and buffered and imputation regions. <br>
				Additionally, as we have samples with mixed ploidy, we will provide the <code>--samples-file</code> parameter, indicating a file containing each sample name and <b>ploidy</b> (one per row).<br>
				
				We run GLIMPSE phase using default parameters that can apply to most datasets. For extremely low coverage and small reference panels, increasing the number of iterations might give more accuracy.
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> mkdir -p GLIMPSE_impute<br>
				&nbsp;> VCF=asw_1x_vcf/merged.chrX.1x.vcf.gz<br>
				&nbsp;> REF=reference_panel/1000GP.chrX.filt.bcf<br>
				&nbsp; >MAP=../maps/genetic_maps.b38/chrX.b38.gmap.gz<br>
				
				&nbsp;> while IFS="" read -r LINE || [ -n "$LINE" ];<br>
				&nbsp;> do<br>
				&nbsp;> &nbsp;&nbsp;printf -v ID "%03d" $(echo $LINE | cut -d" " -f1)<br>	
				&nbsp;> &nbsp;&nbsp;IRG=$(echo $LINE | cut -d" " -f3)<br>
				&nbsp;> &nbsp;&nbsp;ORG=$(echo $LINE | cut -d" " -f4)<br>
				&nbsp;> &nbsp;&nbsp;OUT=GLIMPSE_impute/merged.chrX.imputed.${ID}.bcf<br>
				&nbsp;> &nbsp;&nbsp;./bin/GLIMPSE_phase --input ${VCF} --reference ${REF} --map ${MAP} --input-region ${IRG} --output-region ${ORG} --output ${OUT} --samples-file samples.txt<br>
				&nbsp;> &nbsp;&nbsp;bcftools index -f ${OUT}<br>
				&nbsp;> done < chunks.chrX.txt
				</code></p>
				
				The output is a VCF/BCF file for each imputed chunk. We merge the chunks belonging to the same chromosome together in the next step.
			</div>
		</div>
		
		<div id="run_ligate" class="page-header">
	    	<h1>6. Ligate multiple chunks together</h1>
	    	<p>
				Merging together different chunks of the sample chromosome is a standard procedure and it is usually straightforward in the case of genotype data. 
				However GLIMPSE phase generates phased information in addition of genotype information. 
				In this case, ligation is a required step to merge multiple chunks together without losing phased imputation. 
				For this purpose we developed a software in the GLIMPSE software suite, called GLIMPSE_ligate. 
				The output of this step is a chromosome wide VCF/BCF file containing information coherent phasing information, stored in the FORMAT/HS field
			</p>
	    	<div class="well">
				<h3>6.1. Ligate whole chromosome chunks</h3>
				
				<p>
				GLIMPSE_ligate only requires a list containing the imputed files that need to be merged together: 
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> mkdir -p GLIMPSE_ligate<br>
				&nbsp;> LST=GLIMPSE_ligate/list.chrX.txt<br>
				&nbsp;> ls GLIMPSE_impute/merged.chrX.imputed.*.bcf > ${LST}<br>
				&nbsp;> OUT=GLIMPSE_ligate/merged.chrX.bcf<br>
				&nbsp;> ./bin/GLIMPSE_ligate --input ${LST} --output ${OUT}<br>
				</code></p>		
				<p>In the case phased information is not needed, this can be the final step, providing chromosome-wide genotype information in the FORMAT/DS and FORMAT/GP field.</p>	
			</div>
		</div>
		
		
		<div id="run_sample" class="page-header">
	    	<h1>7. Sample haplotypes</h1>
	    	<p>In the case haplotype-level information is required, GLIMPSE_sample can sample from the FORMAT/HS field accurate, consensus based haplotypes. 
	    	The output of this step is a VCF/BCF file containing information at the chromosome level, where the GT field contains accurate phased information.</p>
	    	<div class="well">
				<h3>7.1. Sample whole chromosome data</h3>
				
				<p>
				There are two main modes for GLIMPSE_sample can operate. 
				The first mode can sample haplotypes based on the probabilities given from the FORMAT/HS field (<i>--sample</i>), while the second mode outputs the most likely haplotypes given the values in the FORMAT/HS field (<i>--solve</i>).
				<br>
				We run GLIMPSE_sample using the <i>--solve</i> mode:
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> mkdir -p GLIMPSE_sample<br>
				&nbsp;> VCF=GLIMPSE_ligate/merged.chrX.bcf<br>
				&nbsp;> OUT=GLIMPSE_sample/merged.chrX.sampled.bcf<br>
				&nbsp;> ./bin/GLIMPSE_sample --input ${VCF} --solve --output ${OUT}<br>
				</code></p>
				<p>From the output dataset, accurate phased information, stored in the GT field can be directly used.	</p>
			</div>
		</div>
		
		<div id="run_concordance" class="page-header">
	    	<h1>8. Check imputation accuracy</h1>
	    	<p>
				Since we downsampled the reads from the original 30x data, we might be interested now in checking how accurate the imputation is, compared the original 30x dataset.
				For this purpose we use the GLIMPSE_concordance tool, which can be used to compute the r<sup>2</sup> correlation between imputed dosages (in MAF bins) and highly-confident genotype calls from the high-coverage dataset.
			</p>
			<div class="well">
				<h3>8.1. Running GLIMPSE_concordance</h3>
				<p>
				The GLIMPSE_concordance requires tool requires a file (--input) indicating: 
				<ol>
					<li>the region of interest;</li>
					<li>a file containing allele frequencies at each site;</li>
					<li>the validation dataset called at the same positions as the imputed file (in a similar way as showed in appendix A1, without the downsampling);</li>
					<li>the imputed data.</li>
				</ol>
				We provide a file called <code>concordance.lst</code> having all the correct files in the right order for this tutorial.
				Other parameters specify how confident we want a site to be in the validation data and the MAF bins.<br>
				
				As we have samples with mixed ploidy, we will run the concordance tool two times, with a difference set of samples: haploids and diploids.<br>				
				
				For haploid samples, the GLIMPSE_concordance too is run as follows:
				<p>
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> ./bin/GLIMPSE_concordance --input concordance.lst --minDP 8 --output GLIMPSE_concordance/output.hap --minPROB 0.9999 \<br>
				&nbsp;>     --bins 0.00000 0.00100 0.00200 0.00500 0.01000 0.05000 0.10000 0.20000 0.50000 \<br>
				&nbsp;>     --af-tag AF_afr --samples asw_1x_bam/asw_samples/NA19703
				</code>
				</p>
				
				For diploid samples, the GLIMPSE_concordance too is run as follows:
				<p>
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> ./bin/GLIMPSE_concordance --input concordance.lst --minDP 8 --output GLIMPSE_concordance/output.dip --minPROB 0.9999 \<br>
				&nbsp;>     --bins 0.00000 0.00100 0.00200 0.00500 0.01000 0.05000 0.10000 0.20000 0.50000 \<br>
				&nbsp;>     --af-tag AF_afr --samples asw_1x_bam/asw_samples/NA19625
				</code>
				</p>	
			</div>
		</div>
    </div> <!-- /container -->
	
  <footer class="footer">
      <div class="container" style="text-align: center;">
        <span class="text-muted">Copyright Â© 2020 University of Lausanne | All Rights Reserved</span>
      </div>
</footer>
</body>
    
