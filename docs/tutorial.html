<!doctype html>
<html lang="en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-162723563-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		gtag('config', 'UA-162723563-1');
	</script>
	
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
		
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="srubinac" >

    <title>GLIMPSE</title>
    <link rel="icon" href="images/branding/glimpse_icon.png">
    
    <!-- Bootstrap core CSS -->
    <link href="./css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="./css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./css/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <!-- JQuery -->
    <script type="text/javascript" src="./script/jquery-1.12.4.min.js"></script>
    <script type="text/javascript" src="./script/bootstrap.min.js"></script>
    <script type="text/javascript" src="./script/docs.min.js"></script>
    <!-- chart JS -->
   	<script type="text/javascript" src="script/Chart.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script type="text/javascript" src="./script/ie10-viewport-bug-workaround.js"></script>
	<!-- Custom styles for this template -->
    <link href="./css/theme.css" rel="stylesheet">
    <!-- Script to load navbar code -->
	<script>
		$(function() {
			$("#navbarbox").load("navbar.html");
		});
    </script> 
</head>

<body>

	<!-- NAVBAR -->
	<nav class="navbar navbar-inverse navbar-fixed-top">
	<div class="container" id="navbarbox"></div>
    </nav>
    
    <!-- CONTENT -->
    <div class="container theme-showcase" role="main">
		<div id="run_preliminaries" class="page-header">
	    	<h1>1. Datasets and preliminaries</h1>
		</div>
		
		<p>
		GLIMPSE is a tool of software for imputation and phasing of low-coverage datasets in the form of <b>genotype gikelihoods</b> (GLs) at all variant positions.
		GLIMPSE requires <a href="http://www.htslib.org/">BCFtools</a> v1.7 (or later) as a requirement, since it makes use of indexed VCF/BCF files. 
		Here we also used BCFtools to compute genotype likelihoods.
		<br>
		<br>
		In this tutorial, we show how to run GLIMPSE from sequencing reads data (BAM/CRAM file) to obtain refined genotype and haplotype calls.
		A small dataset containing chromosome 22 downsampled 1x sequencing reads for one individual (NA12878) is provided with GLIMPSE, 
		together with a reference genome FASTA file (for chromsome 22) needed for genotype likelihood computations.
		<br>
		<br>
		A minimal set of data to run this pipeline can be found in the folder <code>GLIMPSE/test</code>. All datasets used here are in GRCh38/hg38 genome assembly.  
		</p>

		<div class="well">
			<h3>1.1. Setting the environment and binaries</h3>	
			<p>All scripts have been written assuming <code>&nbsp;> cd GLIMPSE/test/</code> as current directory. Therefore, we require to move to the test directory:
			<p style="text-indent:-5px ! important;"><code>&nbsp;> cd GLIMPSE/test/</code></p>
			<p>From this folder we build all the GLIMPSE software needed (chunk, phase, ligate, sample and concordance). 
			For this reason, we require that GLIMPSE can correctly compile on your machine and you might be required to edit the Makefiles manually. 
			See <a href="installation.html">installation instructions</a> if there are any problems at this stage. 
			We created a script to configure a directory containing symbolic links to the GLIMPSE binaries we will need later.
			To run the setup script, simply run:</p>
			<p style="text-indent:-5px ! important;"><code>&nbsp;> ./step1_script_setup.sh</code></p>
			<p>If the script runs correctly, the software compiles and the bin folder containing symbolic links to the binaries has been created, everything is correctly setup.</p>
		</div>
		<div class="well">
			<h3>1.2. Low coverage reads</h3>
				
			<p>
			In this example we downsampled the publicly available 30x data available for NA12878 provided by the 1000 Genomes project (in collaboration with the New York Genomes Center).
			We downloaded the full dataset, kept only chromosome 22 reads and downsampled to 1x. The resulting BAM file can be found in: 
			</p>
			
			<p style="text-indent:-5px ! important;"><code>GLIMPSE/test/NA12878_1x_bam/NA12878.bam[.bai]</code></p>
			
			<p>
			Details of how we downsampled the dataset are provided in appendix section A1.1.
			</p>
		</div>
			    	
		<div id="run_reference_panel" class="page-header">
	    		<h1>2. Reference panel preparation</h1>
		</div> 
		<p>
		In order to run accurate imputation we recommend to use a targeted reference with ancestry related to the target samples, if possible. 
		For this tutorial we use the 1000 Genomes Project phase 3 reference panel. 
		Since the reference panel contains data of our target sample, we need to remove it from the reference panel. 
		This steps downloads the 1000 genomes b38 data from the EBI ftp site.
		</p>
		<div class="well">
			<h3>2.1. Download of the reference panel files</h3>

			<p>
			The 1000 Genomes phase 3 reference panel is publicly available at EBI 1000 genomes ftp site. 
			We can download chromosome 22 data using:
			</p>
		
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/ALL.chr22_GRCh38.genotypes.20170504.vcf.gz{,.tbi}
			</code></p>
			The reference panel size is approximately 200MB.
		</div>
		<div class="well">
			<h3>2.2. Remove NA12878 from the reference panel and perform basic QC</h3>
			<p> 
			We used BCFtools to remove sample NA12878 from the reference panel and we export the dataset in BCF file format (for efficiency reasons). 
			We also performs a basic QC step that includes:
			<ol>
				<li>Generate a text file containing space-spearated old and new chromosome names. This is required to rename the numerical chromosome names with 'chr' tag. Apply the new chromosome names with 'bcftools annotate'.</li>
				<li>Keep only SNPs and remove multiallelic records.</li>
			</ol> 
			The original reference panel files are then deleted from the main test folder:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> for CHR in {1..23} X ; do <br>
			&nbsp;> echo ${CHR} chr${CHR}<br>
			&nbsp;> done >> chr_names.txt<br>
			<br>
			&nbsp;> CHR=22<br>
			&nbsp;> bcftools annotate --rename-chrs chr_names.txt \<br>
			&nbsp;> &nbsp;&nbsp;&nbsp;&nbsp;ALL.chr${CHR}_GRCh38.genotypes.20170504.vcf.gz -Ou | \<br>
			&nbsp;> bcftools view -m 2 -M 2 -v snps -s ^NA12878 --threads 4 -Ob -o reference_panel/1000GP.chr22.noNA12878.bcf<br>
			&nbsp;> bcftools index -f reference_panel/1000GP.chr22.noNA12878.bcf<br>
			&nbsp;> rm ALL.chr22_GRCh38.genotypes.20170504.vcf.gz*<br>
			&nbsp;> rm chr_names.txt<br>
			</code></p>
			
			<p>
			The resulting reference panel files can be found in: 
			</p>
			
			<p style="text-indent:-5px ! important;"><code>GLIMPSE/test/reference_panel/1000GP.chr22.noNA12878.bcf[.csi]</code></p>
			
			<p>
			The reference panel can now be used for genotype likelihoods calculations (only the sites, not the data) and imputation.
			</p>
		</div>
		    
		<div id="run_likelihoods" class="page-header">
	    	<h1>3. Computation of genotype likelihoods</h1>
		</div>
		
		<p>
		GLIMPSE requires input data to take the form of <b>Genotype Likelihoods</b> (GLs).
		GLs need to be computed at all target individuals and <b>all variant sites present in the reference panel</b> of haplotypes used for the imputation.
		In this section, we describe a simple procedure to compute GLs from sequencing data using BCFtools.
		However, other callers, such as GATK for instance, can be also considered as soon as the GLs are encoded in a VCF/BCF file using the FORMAT/PL field.
		<br>
		For this tutorial we only follow step 3.1 and step 3.2, because step 3.3 is not necessary since we have only one target sample in our study panel.
		The code for sections 3.1 and 3.2 is included in the script <code>step2_script_GL.sh</code>.
		</p>
		
		<div class="well">
			<h3>3.1. Extracting variable positions in the reference panel</h3>
				
			<p>
			We want this information to tell BCFtools at which positions to make a call.
			For simplicity here, we only focus on SNPs but GLIMPSE can impute any type of variants as soon it is bi-allelic and has GLs being properly defined.
			To perform the extraction from the chromosome 22 of a reference panel <code>1000GP.chr22.noNA12878.bcf</code>, run first BCFtools as follows:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> bcftools view -G reference_panel/1000GP.chr22.noNA12878.bcf -Oz -o reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz<br>
			&nbsp;> bcftools index -f reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz
			</code></p>
			
			<p>Then, convert the output file <code>1000GP.chr22.noNA12878.sites.vcf.gz</code> into TSV format and index the file using tabix (requires htslib in PATH), using this command:</p>
			
			<p style="text-indent:-5px ! important;"><code> 
			&nbsp;> bcftools query -f'%CHROM\t%POS\t%REF,%ALT\n' reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz | bgzip -c > reference_panel/1000GP.chr22.noNA12878.sites.tsv.gz<br>
			&nbsp;> tabix -s1 -b2 -e2 reference_panel/1000GP.chr22.noNA12878.sites.tsv.gz
			</code></p>
			
			<p>In a general pipeline, we should generate this pair of files (*.vcf.gz + *.tsv.gz) for all chromosome separately.</p>
		</div>
		
		<div class="well">
			<h3>3.2. Computing GLs for a single individual at specific positions</h3>

			<p>
			Once ready the position files, we can then start doing the calling in itself.
			We use the downsampled 1x BAM file generated in section 1.1 <code>NA12878_1x_bam/NA12878.chr22.1x.bam</code>.
			<br>
			BCFtools requires the reference genome in order to align the BAM file. We used the reference genome version used by the 1000 Genomes Project (<code>reference_genome/hs38DH.chr22.fa.gz[fai,gzi]</code>)
			<br>
			We can run the following command:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> BAM=NA12878_1x_bam/NA12878.bam<br>
			&nbsp;> VCF=reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz<br>
			&nbsp;> TSV=reference_panel/1000GP.chr22.noNA12878.sites.tsv.gz<br>
			&nbsp;> REFGEN=reference-genome/hs38DH.chr22.fa.gz<br>
			&nbsp;> OUT=NA12878_1x_vcf/NA12878.chr22.1x.vcf.gz<br>			
			&nbsp;> bcftools mpileup -f ${REFGEN} -I -E -a 'FORMAT/DP' -T ${VCF} -r chr22 ${BAM} -Ou | bcftools call -Aim -C alleles -T ${TSV} -Oz -o ${OUT} <br>
			&nbsp;> bcftools index -f ${OUT}<br>
			</code></p>
			
			<p>Note here, that we use <code>-T reference_panel/1000GP.chr22.noNA12878.sites.<b>vcf</b>.gz</code> in the first part of the command line and <code>-T reference_panel/1000GP.chr22.noNA12878.sites.<b>tsv</b>.gz</code> in the second part of the command line.</p>
			<p>You may also tune the options of BCFtools to your specific needs, requirements and data.</p>
			<p>As an output of this step we have a VCF file format containing genotype likelihoods at each site in the reference panel. </p>
		</div>
		<div class="well">
			<h3>3.3. Merging genotype likelihoods of multiple individuals</h3>
			<p>In the case of multiple target individuals, an additional step, <b>not required in this pipeline</b>, is to generate a single file containing genotype likelihoods for all target individuals. 
			This can be easily done using BCFtools, for example:
			</p>
			
			<p style="text-indent:-5px ! important;"><code>
			&nbsp;> bcftools merge -m none -r 22 -Oz -o merged.chr22.1x.vcf.gz -l list.txt<br>
			</code></p>
			
			<p>Where <code>list.txt</code> is a text file containing the full list of VCF/BCF files containing GLs of each target individual in the study, one individual file per line. 
			The resulting file must be indexed and can be used in the subsequent steps of the pipeline.</p>
			
		</div>
		
		<div id="run_chunk" class="page-header">
	    	<h1>4. Split the genome into chunks</h1>
		</div>
		
		<p>
		One important step prior is to define the chunks where to run imputation and phasing. 
		This step is not trivial because different long regions increase the running time, but small regions can drastically decrease accuracy. 
		Also there are several variables to take into account: the amount of missingness in the defined region and the length in Mb. 
		For these reasons we developed a tool in the GLIMPSE suite (GLIMPSE_chunk) that is able to quickly generate imputation chunks taking into account all this information.
		</p>
		
		<div class="well">
			<h3>4.1. Chunking a chromosome</h3>
				
			<p>
			We use GLIMPSE_chunk to generate imputation regions for the full chromosome 22, modifying few default parameters in this way:
			</p>
			
			<p style="text-indent:-5px ! important;"><code> 
			&nbsp;> bin/GLIMPSE_chunk --input reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz --region chr22 --window-size 2000000 --buffer-size 200000 --output chunks.chr22.txt
			</code></p>			
			This generates a file containing the imputation chunks and larger chunks including buffers that we will use to run GLIMPSE_phase. 		
		</div>
		
		<div id="run_phase" class="page-header">
	    	<h1>5. Impute and phase a whole chromosome</h1>
	    	<p>
	    	The core of GLIMPSE is the GLIMPSE_phase method. The algorithm works by iteratively refining the genotype likelihoods of the target individuals in the study. 
	    	The output of the method is a VCF/BCF file containing:
	    	<ul>
	    		<li>the best guess genotype in the FORMAT/GT field
	    		<li>the imputed genotype dosage in the FORMAT/DS field
	    		<li>the genotype probabilities in the FORMAT/GP field
	    		<li>the last (max 15) sampled haplotypes in the FORMAT/HS field
	    	</ul> 
	    	Other relevant information include the INFO score computed at each variant against the reference panel allele frequency and the estimated allele frequency, obtained from the genotype dosages (and <b>not</b> from the best guess genotypes).
	    	</p>
	    	<div class="well">
				<h3>5.1. Running GLIMPSE</h3>
				
				<p>
				To run GLIMPSE_phase we only need to run a job for each imputation chunk. Each job runs on 8 threads in this example. 
				Input data are the dataset containing the genotype likelihoods, a reference panel of haplotypes, a fine-scale genetic map (e.g. from the International HapMap project) and buffered and imputation regions. 
				We run GLIMPSE phase using default parameters that can apply to most datasets. For extremely low coverage and small reference panels, increasing the number of iterations might give more accuracy.
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> VCF=NA12878_1x_vcf/NA12878.chr22.1x.vcf.gz<br>
				&nbsp;> REF=reference_panel/1000GP.chr22.noNA12878.bcf<br>
				&nbsp;> MAP=../maps/genetic_maps.b37/chr22.b37.gmap.gz<br>
				
				&nbsp;> while IFS="" read -r LINE || [ -n "$LINE" ];<br>
				&nbsp;> do<br>
				&nbsp;> &nbsp;&nbsp;printf -v ID "%02d" $(echo $LINE | cut -d" " -f1)<br>	
				&nbsp;> &nbsp;&nbsp;IRG=$(echo $LINE | cut -d" " -f3)<br>
				&nbsp;> &nbsp;&nbsp;ORG=$(echo $LINE | cut -d" " -f4)<br>
				&nbsp;> &nbsp;&nbsp;OUT=GLIMPSE_imputed/NA12878.chr22.1x.${ID}.bcf<br>
				&nbsp;> &nbsp;&nbsp;bin/GLIMPSE_phase --input ${VCF} --reference ${REF} --map ${MAP} --input-region ${IRG} --output-region ${ORG} --output ${OUT} --thread 8<br>
				&nbsp;> &nbsp;&nbsp;bcftools index -f ${OUT}<br>
				&nbsp;> done < chunks.chr22.txt
				</code></p>
				
				The output is a VCF/BCF file for each imputed chunk. We merge the chunks belonging to the same chromosome together in the next step.
			</div>
		</div>
		
		<div id="run_ligate" class="page-header">
	    	<h1>6. Ligate multiple chunks together</h1>
	    	<p>
				Merging together different chunks of the sample chromsome is a standard procedure and it is usually straightforward in the case of genotype data. 
				However GLIMPSE phase generates phased information in addition of genotype information. 
				In this case, ligation is a required step to merge multiple chunks together without losing phased imputation. 
				For this purpose we developed a software in the GLIMPSE software suite, called GLIMPSE_ligate. 
				The output of this step is a chromosome wide VCF/BCF file containing information coherent phasing information, stored in the FORMAT/HS field
			</p>
	    	<div class="well">
				<h3>6.1. Ligate whole chromosome chunks</h3>
				
				<p>
				GLIMPSE_ligate only requires a list containing the imputed files that need to be merged together: 
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> LST=GLIMPSE_ligated/list.chr22.txt<br>
				&nbsp;> ls GLIMPSE_imputed/NA12878.chr22.imputed.*.bcf > ${LST}<br>
				&nbsp;> OUT=GLIMPSE_ligated/NA12878.chr22.merged.bcf<br>
				&nbsp;> bin/GLIMPSE_ligate --input ${LST} --output $OUT<br>
				&nbsp;> bcftools index -f ${OUT}
				</code></p>		
				<p>In the case phased information is not needed, this can be the final step, providing chromosome-wide genotype information in the FORMAT/DS and FORMAT/GP field.</p>	
			</div>
		</div>
		
		
		<div id="run_sample" class="page-header">
	    	<h1>7. Sample haplotypes</h1>
	    	<p>In the case haplotype-level information is required, GLIMPSE_sample can sample from the FORMAT/HS field accurate, consensus based haplotypes. 
	    	The output of this step is a VCF/BCF file containing information at the chromosome level, where the GT field contains accurate phased information.</p>
	    	<div class="well">
				<h3>7.1. Sample whole chromosome data</h3>
				
				<p>
				There are two main modes for GLIMPSE_sample can operate. 
				The first mode can sample haplotypes based on the probabilities given from the FORMAT/HS field (<i>--sample</i>), while the second mode outputs the most likely haplotypes given the values in the FORMAT/HS field (<i>--solve</i>).
				<br>
				We run GLIMPSE_sample using the <i>--solve</i> mode:
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> VCF=GLIMPSE_ligated/NA12878.chr22.merged.bcf<br>
				&nbsp;> OUT=GLIMPSE_phased/NA12878.chr22.phased.bcf<br>
				&nbsp;> bin/GLIMPSE_sample --input ${VCF} --solve --output ${OUT}<br>
				&nbsp;> bcftools index -f ${OUT}
				</code></p>
				<p>From the output dataset, accurate phased information, stored in the GT field can be directly used.	</p>
			</div>
		</div>
		
		<div id="run_concordance" class="page-header">
	    	<h1>8. Check imputation accuracy</h1>
	    	<p>
				Since we downsampled the reads from the original 30x data, we might be interested now in checking how accurate the imputation is, compared the original 30x dataset.
				For this purpose we use the GLIMPSE_concordance tool, which can be used to compute the r<sup>2</sup> correlation between imputed dosages (in MAF bins) and highly-confident genotype calls from the high-coverage dataset.
			</p>
			<div class="well">
				<h3>8.1. Running GLIMPSE_concordance</h3>
				<p>
				The GLIMPSE_concordance requires tool requires a file (--input) indicating: 
				<ol>
					<li>the region of interest;</li>
					<li>a file containing allele frequencies at each site;</li>
					<li>the validation dataset called at the same positions as the imputed file (in a similar way as showed in appendix A1, without the downsampling);</li>
					<li>the imputed data.</li>
				</ol>
				We provide a file called <code>concordance.lst</code> having all the correct files in the right order for this test example.
				Other parameters specify how confident we want a site to be in the validation data and the MAF bins.<br>
				The GLIMPSE_concordance too can be run as follows:
				<p>
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> ./bin/GLIMPSE_concordance --input concordance.lst --minDP 8 --output GLIMPSE_concordance/output --minPROB 0.9999 \<br>
				&nbsp;>     --bins 0.00000 0.00100 0.00200 0.00500 0.01000 0.02000 0.05000 0.10000 0.15000 0.20000 0.25000 0.30000 0.35000 0.40000 0.45000 0.50000 \<br>
				&nbsp;>     --info_af AF_nfe --thread 4
				</code></p>	
			</div>
			<div class="well">
				<h3>8.2. Visualising the results</h3>
				<p>
				The GLIMPSE_concordance folder contains several files describing the quality of the imputation. In particular, we are interested in the file <code>GLIMPSE_concordance/output.rsquare.grp.txt.gz</code>. 
				We can visualise the results by going in the <code>plot</code> folder and running: 
				</p>
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> ./concordance_plot.py
				</code></p>	
				
				<p style="text-indent:-5px ! important;">
				<div style="text-align: center;"><img src="images/test/accplot.png" width="600" height="480" alt="Accuracy plot"></div>
				</code>
				<p>
				The command requires python3 and matplotlib installed.<br>
				The plot shows that the 1000 Genomes reference panel can be used to impute accurately variants up to ~1% MAF and there is a drop at rare variants, as expected.
				</p>
			</div>
		</div>
		
		<div id="run_sample" class="page-header">
	    	<h1>A1. Low coverage reads</h1>
	    	<div class="well">
				<h3>A1.1. Downsample 1000 Genome Project NYGC high coverage data</h3>
				
				<p>
				30x data for NA12878 has been made available by the New York Genome Center and the 1000 Genomes project. Please refer to the official documentation to download the data:
				</p>
			
				<p style="text-indent:-5px ! important;"><code>
				https://www.internationalgenome.org/data-portal/data-collection/30x-grch38
				</code></p>
				<p>
				Once the CRAM file (and index) have been downloaded, we create our validation dataset for chromosome 22 using samtools and bcftools (assuming the reference panel has already been downloaded and step 3.1. has already been performed):
				</p>
				
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> samtools view -T reference-genome/hs38DH.chr22.fa.gz -bo GLIMPSE_validation/NA12878.bam NA12878.final.cram chr22 <br>
				&nbsp;> samtools index GLIMPSE_validation/NA12878.bam <br>
				</code></p>
				
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> BAM=GLIMPSE_validation/NA12878.bam<br>
				&nbsp;> VCF=reference_panel/1000GP.chr22.noNA12878.sites.vcf.gz<br>
				&nbsp;> TSV=reference_panel/1000GP.chr22.noNA12878.sites.tsv.gz<br>
				&nbsp;> REFGEN=reference-genome/hs38DH.chr22.fa.gz<br>
				&nbsp;> OUT=GLIMPSE_validation/NA12878.chr22.validation.bcf<br>			
				&nbsp;> bcftools mpileup -f ${REFGEN} -I -E -a 'FORMAT/DP' -T ${VCF} -r chr22 ${BAM} -Ou | bcftools call -Aim -C alleles -T ${TSV} -Ob -o ${OUT}<br>
				&nbsp;> bcftools index -f ${OUT}<br>
				&nbsp;> rm GLIMPSE_validation/NA12878.bam*
				</code></p>
				
				<p>Finally, we can downsample the 30x data to low coverage (1x) using samtools </p>
				
				<p style="text-indent:-5px ! important;"><code>
				&nbsp;> samtools view -T reference-genome/hs38DH.chr22.fa.gz -s 1.03045 -bo NA12878_1x_bam/NA12878.bam NA12878.final.cram chr22<br>
				&nbsp;> samtools index NA12878_1x_bam/NA12878.bam <br>
				&nbsp;> rm NA12878.final.cram*
				</code></p>
				
				<p>The output datasets <code>NA12878_1x_bam/NA12878.bam</code> and <code>GLIMPSE_validation/NA12878.chr22.validation.bcf</code> are the files provided in the GLIMPSE test folder.
				</p>
			</div>
		</div>
    </div> <!-- /container -->
	
  <footer class="footer">
      <div class="container" style="text-align: center;">
        <span class="text-muted">Copyright Â© 2020 University of Lausanne | All Rights Reserved</span>
      </div>
</footer>
</body>
    